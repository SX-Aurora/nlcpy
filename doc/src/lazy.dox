#
# # NLCPy License #
#
#     Copyright (c) 2020 NEC Corporation
#     All rights reserved.
#
#     Redistribution and use in source and binary forms, with or without
#     modification, are permitted provided that the following conditions are met:
#     * Redistributions of source code must retain the above copyright notice,
#       this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright notice,
#       this list of conditions and the following disclaimer in the documentation
#       and/or other materials provided with the distribution.
#     * Neither NEC Corporation nor the names of its contributors may be
#       used to endorse or promote products derived from this software
#       without specific prior written permission.
#
#     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
#     ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
#     WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
#     FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
#     (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
#     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
#     ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
#     (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
#     SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

## 
# @if(lang_ja)
# @else
# @page lazy Lazy Evaluation
#
# <h1> Overview </h1>
#
# SX-Aurora TSUBASA consists of x86 Node(VH) and Vector Engine(VE), 
# which are directly connected with PCI Express.
# When data transfer between VH and VE frequently appears in Python 
# scripts, its performance becomes significantly slower.
# In other words, the overhead between VH and VE is quite an important 
# issue to make Python scripts performed faster.
# As a solution for it, NLCPy evaluates Python scripts lazy to reduce 
# the number of offloading requests.
#	
# @image html "lazy_evaluation.bmp"
#
# Evaluation sequence is as follows:
#    <ol>
#      <li> Stack kernel requests on VH.
#      <li> Flush the kernel requests to VE when a trigger appears in a Python scripts.
#      <li> Start computations on VE based on the kernel requests and wait until computations will be completed.
#    </ol>
#
# <h1> Flush Triggers </h1>
#    Relevant triggers are as follows:
#      <ul>
#      <li> When the data transfer from VE to VH is occurred. @n 
#           (e.g. @ref core::get "ndarray.get", 
#                 print with @ref n-dimensional_array "ndarray", 
#                 comparison between @ref n-dimensional_array "ndarray" 
#                 and Python scalar). @n
#      <li> When a number of stacked requests on VH exceeds 100.
#      <li> When one of the following functions is called.
#        <ul>
#          <li> @ref request::flush "nlcpy.request.flush"
#          <li> \__getitem__/__setitem__ from/to ndarray with boolean mask.
#          <li> @ref ufunc::reduceat "nlcpy.ufunc.reduceat".
#          <li> @ref ufuncs::power "nlcpy.power" if types of input arrays are integers.
#        </ul>
#      </ul>
#
# <h1> Request Managing </h1>
#    If you want to manage offload timing, 
#    see @ref RequestManaging "Request Managing Routines". @n
#
# <h1> Debugging Tips </h1>
#    When using lazy evaluation, the position of warnings where
#    your Python script raised may not be accurate.
#    So if you want to know the exact position of warnings, we recommend using @ref request::set_offload_timing_onthefly "nlcpy.request.set_offload_timing_onthefly".
#
#    @par Warning example with "lazy"
#    @code
#    # sample.py
#    import nlcpy as vp
#    a = vp.divide(1, 0) # divide by zero warning
#    b = a + 1
#    print(b)
#    @endcode
#    @verbatim
#    $ python sample.py
#    sample.py:5: RuntimeWarning: divide by zero encountered in nlcpy.core.core
#      print(b)
#    inf
#    @endverbatim
#
#    @par Warning example with "on-the-fly"
#    @code
#    # sample.py
#    import nlcpy as vp
#    vp.request.set_offload_timing_onthefly()
#    a = vp.divide(1, 0) # divide by zero warning
#    b = a + 1
#    print(b)
#    @endcode
#    @verbatim
#    $ python sample.py
#    sample.py:4: RuntimeWarning: divide by zero encountered in nlcpy.core.core
#      a = vp.divide(1, 0) # divide by zero warning
#    inf
#    @endverbatim
#
##
# <h1> Performance Comparison between "on-the-fly" and "lazy" </h1>
#    Here, we show simple performance comparison between "on-the-fly" and "lazy".@n
#    In this case, using "lazy" improves performance about 2.5 times.
#    @par Sample Program for Comparison
#    @code
#    # comparison.py
#    import nlcpy as vp
#    import time
#    
#    N = 10000
#    
#    timings = [
#        vp.request.set_offload_timing_onthefly,
#        vp.request.set_offload_timing_lazy,
#              ]
#    
#    for t in timings:
#        t() # set offload timing
#        print(vp.request.get_offload_timing())
#        x = vp.zeros(N, dtype='i8')
#        vp.request.flush()
#        begin = time.time()
#        for i in range(N):
#            x[i] += i
#        vp.request.flush()
#        end = time.time()
#        print(x)
#        print("elapsed time =", end - begin, "\n")
#    @endcode
#
#    @par Execution Result
#    @verbatim
#    $ python comparison.py
#    current offload timing is 'on-the-fly'
#    [   0    1    2 ... 9997 9998 9999]
#    elapsed time = 1.1336500644683838
#    
#    current offload timing is 'lazy'
#    [   0    1    2 ... 9997 9998 9999]
#    elapsed time = 0.4292490482330322
#    @endverbatim
#
## @endif
#
#      
