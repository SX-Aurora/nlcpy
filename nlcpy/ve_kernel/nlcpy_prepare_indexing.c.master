/*
#
# * The source code in this file is developed independently by NEC Corporation.
#
# # NLCPy License #
#
#     Copyright (c) 2020-2021 NEC Corporation
#     All rights reserved.
#
#     Redistribution and use in source and binary forms, with or without
#     modification, are permitted provided that the following conditions are met:
#     * Redistributions of source code must retain the above copyright notice,
#       this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright notice,
#       this list of conditions and the following disclaimer in the documentation
#       and/or other materials provided with the distribution.
#     * Neither NEC Corporation nor the names of its contributors may be
#       used to endorse or promote products derived from this software
#       without specific prior written permission.
#
#     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
#     ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
#     WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
#     DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
#     FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
#     (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
#     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
#     ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
#     (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
#     SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
*/
@#include <stdio.h>
@#include <stdint.h>
@#include <stdbool.h>
@#include <stdlib.h>
@#include <limits.h>
@#include <alloca.h>
@#include <assert.h>

#include "nlcpy.h"

uint64_t nlcpy_prepare_indexing(ve_arguments *args, int32_t *psw) {
    ve_array *s = &(args->prepare_indexing.s);
    ve_array *reduced_idx = &(args->prepare_indexing.reduced_idx);
    int64_t a_shape_i = args->prepare_indexing.a_shape_i;
    int64_t stride = args->prepare_indexing.stride;

    assert(s->size == reduced_idx->size);
    assert(s->ndim == reduced_idx->ndim);
    assert(s->dtype == reduced_idx->dtype);
    assert(s->dtype == ve_i64);

    int64_t *pdx = (int64_t *)reduced_idx->ve_adr;
    if  (pdx == NULL) {
        pdx = (int64_t *)nlcpy__get_scalar(reduced_idx);
        if (pdx == NULL) {
            return NLCPY_ERROR_MEMORY;
        }
    }
    int64_t *ps = (int64_t *)s->ve_adr;
    if  (ps == NULL) {
        ps = (int64_t *)nlcpy__get_scalar(s);
        if (ps == NULL) {
            return NLCPY_ERROR_MEMORY;
        }
    }

/////////
// 0-d //
/////////
    if (reduced_idx->ndim == 0) {
@#ifdef _OPENMP
@#pragma omp single
@#endif /* _OPENMP */
{
        int64_t fd = (a_shape_i != 0) ? floor(ps[0] / a_shape_i) : 0;
        pdx[0] += stride * (ps[0] - fd * a_shape_i);
} /* omp single */

/////////
// 1-d //
/////////
    } else if (reduced_idx->ndim == 1) {
@#ifdef _OPENMP
@#pragma omp single
@#endif /* _OPENMP */
{
        int64_t i;
        int64_t n_inner = 0;
        uint64_t ix0 = s->strides[n_inner] / s->itemsize;
        uint64_t iy0 = reduced_idx->strides[n_inner] / reduced_idx->itemsize;
        for (i = 0; i < reduced_idx->shape[n_inner]; i++) {
            int64_t fd = (a_shape_i != 0) ? floor(ps[i*ix0] / a_shape_i) : 0;
            pdx[i*iy0] += stride * (ps[i*ix0] - fd * a_shape_i);
        }
} /* omp single */

/////////
// N-d //
/////////
    } else if (reduced_idx->ndim > 1 && reduced_idx->ndim <= NLCPY_MAXNDIM){
@#ifdef _OPENMP
@#pragma omp single
@#endif /* _OPENMP */
{
        // TODO: refine code
        nlcpy__exchange_shape_and_strides(s);
        nlcpy__exchange_shape_and_strides(reduced_idx);
} /* omp single */

@#ifdef _OPENMP
        const int nt = omp_get_num_threads();
        const int it = omp_get_thread_num();
@#else
        const int nt = 1;
        const int it = 0;
@#endif /* _OPENMP */
        int64_t *cnt_x = (int64_t*)alloca(sizeof(int64_t)*s->ndim);
        int64_t i, j, k;
        int64_t n_inner = s->ndim - 1;
        int64_t n_outer = 0;
        nlcpy__reset_coords(cnt_x, s->ndim);

        uint64_t ix = 0;
        uint64_t iy = 0;
        uint64_t ix0 = s->strides[n_inner] / s->itemsize;
        uint64_t iy0 = reduced_idx->strides[n_inner] / reduced_idx->itemsize;
        const int64_t lenm = s->shape[n_outer];
        const int64_t cntm_s = lenm * it / nt;
        const int64_t cntm_e = lenm * (it + 1) / nt;
        for (int64_t cntm = cntm_s; cntm < cntm_e; cntm++) {
            ix = cntm * s->strides[n_outer] / s->itemsize;
            iy = cntm * reduced_idx->strides[n_outer] / reduced_idx->itemsize;
            for (;;) {
                // most inner loop for vectorize
                for (i = 0; i < s->shape[n_inner]; i++) {
                    int64_t fd = (a_shape_i != 0) ? floor(ps[i*ix0+ix] / a_shape_i) : 0;
                    pdx[i*iy0+iy] += stride * (ps[i*ix0+ix] - fd * a_shape_i);
                }
                // set next index
                for (k = n_inner-1; k >= 1; k--) {
                    if (++cnt_x[k] < s->shape[k]) {
                        ix += s->strides[k] / s->itemsize;
                        iy += reduced_idx->strides[k] / reduced_idx->itemsize;
                        break;
                    }
                    cnt_x[k] = 0;
                    ix -= (s->strides[k] / s->itemsize) * (s->shape[k] - 1);
                    iy -= (reduced_idx->strides[k] / reduced_idx->itemsize) * (reduced_idx->shape[k] - 1);
                }
                if (k < 1) break;
            }
        }
    } else {
        return (uint64_t)NLCPY_ERROR_NDIM;
    }

    retrieve_fpe_flags(psw);
    return (uint64_t)NLCPY_ERROR_OK;
}



